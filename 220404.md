# 220404ğŸ•



## **ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬(Long Short-Term Memory, LSTM)**



ë‹¤ì–‘í•œ ëª¨ë¸ ìƒì„±í•´ë³´ê¸°

- model_lstm_sig : activation function ì„ sigmoid ë¡œ ì ìš©
- model_lstm : activation :tanh
- model_gru : rnn(GRU)
- model_lstm_gru : lstm + gru 2ê°œ ë ˆì´ì–´ë¡œ í•™ìŠµ

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# data ìƒì„±
np.random.seed(2022)

x = np.arange(30 * 12 + 1)
month_time = (x % 30) / 30
y = 20 * np.where(month_time < 0.5, 
                          np.cos(2 * np.pi * month_time),
                          np.cos(2 * np.pi * month_time) + np.random.random(361))

# data ê·¸ë˜í”„
plt.figure(figsize = (10, 5)) 
plt.plot(np.arange(0, 30 * 11 + 1), y[:30 * 11 + 1])

# data scaling
# y -> dataframe
df = pd.DataFrame(index = x, data = y, columns=["time_cos"])

# minmax scale
# y ë°ì´í„°ë¥¼ train set ìœ¼ë¡œ ë§Œë“¤ì–´ ì£¼ê¸° ìœ„í•´ minmax scaler(40 ~ -20 -> 1 ~ -1), time series data (RNN) ë¡œ ë³€ê²½í•´ì¤€ë‹¤.
# regression : x(ë…ë¦½ë³€ìˆ˜) -> y(ì¢…ì†ë³€ìˆ˜)
# seqdata ì˜ˆì¸¡ : x(x1, x2, x3, x4) -> x (x5) ì˜ˆì¸¡

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler() # ê°ì²´ ìƒì„±
scaler.fit(df) # ë°ì´í„°ì— ë§ê²Œ ê°ì²´ fit
s_train = scaler.transform(df) # ë°ì´í„° scaling

# generator ìƒì„±
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
length = 30
generator = TimeseriesGenerator(s_train, s_train, length=length, batch_size = 1)

# model ìƒì„±
# model_lstm_sig : activation function ì„ sigmoid ë¡œ ì ìš©
model_lstm_sig = tf.keras.models.Sequential(name="model_lstm_sig")
model_lstm_sig.add(tf.keras.layers.LSTM(30, activation="sigmoid", input_shape=(30,1)))
model_lstm_sig.add(tf.keras.layers.Dense(1))

model_lstm_sig.compile(optimizer= "adam", loss ="mse")

# model_lstm : activation :tanh
model_lstm = tf.keras.models.Sequential(name="model_lstm")
model_lstm.add(tf.keras.layers.LSTM(30, input_shape=(30,1)))
model_lstm.add(tf.keras.layers.Dense(1))

model_lstm.compile(optimizer= "adam", loss ="mse")

# model_gru : rnn(GRU)
model_gru = tf.keras.models.Sequential(name="model_gru")
model_gru.add(tf.keras.layers.GRU(30, input_shape=(30,1)))
model_gru.add(tf.keras.layers.Dense(1))

model_gru.compile(optimizer= "adam", loss ="mse")

# model_lstm_gru : lstm + gru 2ê°œ ë ˆì´ì–´ë¡œ í•™ìŠµ
model_lstm_gru = tf.keras.models.Sequential(name="model_lstm_gru")
model_lstm_gru.add(tf.keras.layers.LSTM(30, return_sequences=True, input_shape=(30,1))) #return sequence ë¥¼ í†µí•´ RNN ê³„ì—´ì˜ layer ë¼ë¦¬ ì—°ê²° ê°€ëŠ¥
model_lstm_gru.add(tf.keras.layers.GRU(30))
model_lstm_gru.add(tf.keras.layers.Dense(1))

model_lstm_gru.compile(optimizer= "adam", loss ="mse")

# ë°˜ë³µë¬¸ì„ í†µí•´ì„œ 4ê°œì˜ model ì„ generatorì— ëŒ€í•´ í•™ìŠµì‹œí‚¨ë‹¤. 
model_list = [model_lstm_sig, model_lstm, model_gru, model_lstm_gru]
for i in model_list:
  i.fit(generator, epochs = 4)
# ì˜ˆì¸¡ ê³¼ì •: 0~29 -> 30 ì˜ˆì¸¡, 1~30 -> 31 ì˜ˆì¸¡, 2~31 -> 32 ì˜ˆì¸¡


```

predict í›„ ì‹œê°í™”

```python
# ë°˜ë³µë¬¸ì„ í†µí•´ì„œ predict
df_2 = df.drop(df.index[:length])
for i in model_list:
  tmp = i.predict(generator)
  tmp_2 = scaler.inverse_transform(tmp)
  df_2[i.name] = tmp_2
  print(i.name)

df_2
```

![image-20220406165134972](220404.assets/image-20220406165134972.png)

```python
# ëª¨ë¸ ë³„ predict ê·¸ë˜í”„
# ê·¸ë˜í”„ 1
plt.figure(figsize=(25,10))
n=1
for i in df_2.columns:
  ax = plt.subplot(len(df_2.columns), 1, n) # 1ê°œì˜ ì—´, df_2 ì»¬ëŸ¼ì˜ ê°¯ìˆ˜ë§Œí¼ í–‰, n : ì–´ë””ì— ìœ„ì¹˜ í•˜ëŠ”ì§€ 
  plt.title(f"{i}", fontsize = 15)
  plt.ylim(-30,40)# y ê°’ ê³ ì •
  ax.plot(df_2.index, df_2[i], label= str(i)) # xì¶•ì€ df_2.index, y ì¶•ê°’ì€ ì˜ˆì¸¡í•œê°’
  n += 1
plt.tight_layout()

# ê·¸ë˜í”„ 2
ax = plt.subplot(1, 1, 1)
plt.title("time_cos", fontsize = 15)
ax.plot(df_2.index, df_2["time_cos"], label= "time_cos")

plt.figure(figsize=(25,25))
n=1
for i in df_2.columns:
  ax = plt.subplot(len(df_2.columns), 1, n) # 1ê°œì˜ ì—´, df_2 ì»¬ëŸ¼ì˜ ê°¯ìˆ˜ë§Œí¼ í–‰, n : ì–´ë””ì— ìœ„ì¹˜ í•˜ëŠ”ì§€ 
  plt.title(f"{i}", fontsize = 15)
  plt.ylim(-20,40)# y ê°’ ê³ ì •
  ax.plot(df_2.index, df_2[i], label= str(i)) # xì¶•ì€ df_2.index, y ì¶•ê°’ì€ ì˜ˆì¸¡í•œê°’
  n += 1
plt.tight_layout()

```

![image-20220406165310234](220404.assets/image-20220406165310234.png)

![image-20220406165334032](220404.assets/image-20220406165334032.png)

forecast ê·¸ë˜í”„

```python
plt.figure(figsize=(25,10))
for j in model_list:
  forecast = [] #ì˜ˆì¸¡ê°’ ì €ì¥
  batch = s_train[-30:]
  current_batch = batch.reshape((1,30,1))
  forecast_index = np.arange(360,410, step = 1)
  for i in range(50): #360ì—ì„œ 410 ê¹Œì§€ ì˜ˆì¸¡
    current_pred = j.predict(current_batch)[0]
    forecast.append(current_pred)
    # ì›ë˜ ë°ì´í„° 331~360 ì—ì„œ 331 ì œê±°, ë’¤ì— 361 ì¶”ê°€ 
    current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)
  forecast = scaler.inverse_transform(forecast)

  plt.plot(df.index, df["time_cos"])
  plt.plot(forecast_index, forecast, label = f"{j.name}")
  plt.legend(loc="upper right")
```

![image-20220406165355313](220404.assets/image-20220406165355313.png)

model_lstm_gruë¡œ forecast

```python
# ì˜ˆì¸¡
# 331~360(batch)  -> 361 (forecast ì— ì €ì¥)
# 332~361  -> 362
# 333~362  -> 363

forecast = [] #ì˜ˆì¸¡ê°’ ì €ì¥
batch = s_train[-30:]
current_batch = batch.reshape((1,30,1))
forecast_index = np.arange(360,410, step = 1)
for i in range(50): #360ì—ì„œ 410 ê¹Œì§€ ì˜ˆì¸¡
  current_pred = model_lstm_gru.predict(current_batch)[0]
  forecast.append(current_pred)
  # ì›ë˜ ë°ì´í„° 331~360 ì—ì„œ 331 ì œê±°, ë’¤ì— 361 ì¶”ê°€ 
  current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)
forecast = scaler.inverse_transform(forecast)

plt.plot(df.index, df["time_cos"])
plt.plot(forecast_index, forecast)

current_pred = model_lstm_gru.predict(current_batch)[0]
current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)
current_batch
```

![image-20220406165716907](220404.assets/image-20220406165716907.png)



---

- ONNX (Open Neural Network Exchange)