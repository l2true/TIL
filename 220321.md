# 220321 🍕



## 손글씨 숫자 인식



### 1. 기본 개념

- 이미지 -> element가 RGB(3채널), Gray scale(단일채널: 0~255) 등으로 이루어진 행렬

- 숫자처럼 보이는 손글씨를 어떤 숫자인지 맞추는 문제 : classification

  - Data(feature): input으로 넣는 이미지 행렬의 numerical 값들 ex) 이미지 5

  - Label: feature가 분류되는 output (0~9) -> categorical 변수 ex) 숫자 5

- Logistic Regression:  numeic + categorical
  - Linear Regression -> numeric + numeric



### 2. 사용 데이터셋: MNIST

- 손글씨 숫자 이미지 집합
- 실험용 데이터로 많이 사용됨
- 0~9까지의 숫자 이미지로 구성 (훈련: 60,000장, 시험: 10,000장)
- 28 * 28 크기의 회색조 이미지 (1채널, 0~255까지의 값)



### 3. 신경망 구현

1. **Data set Load** 

   - `load_mnist()`: return `train`(Data/Label), `test`(Data/Label)

     - `flatten`:  입력 이미지를 3차원에서 1차원 배열(평탄값)로 변환 (1 * 28 * 28 -> 1 * 784)

     - `normalize`(정규화): 입력 이미지의 픽셀값을 0~255 -> 0~1의 범위로 변환
       - 장점: Buff overflow 방지, 학습 성능 높아짐

   - `one_hot_label` : 레이블을 원-핫(one-hot) 배열로 반환
     - one-hot 배열: 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열 (기본값은 False)
   - `fromarray` : 넘파이로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환

```PYTHON
!pip install pillow 

# sys 모듈을 이용해 부모 디렉토리의 파일을 가져오기
import sys, os
sys.path.append("./code/")

# dataset 디렉토리 안의 mnist.py 파일에서 load_mnist함수를 가져오기
from dataset.mnist import load_mnist 
import numpy as np
from PIL import Image

def img_show(img):
    pil_img=Image.fromarray(np.uint8(img))
#   pil_img.show()
    return pil_img

# dataset load - load_mnist함수: MNist 데이터를 훈련/테스트 데이터로 반환
(x_train, t_train),(x_test, t_test) = load_mnist(flatten = True, normalize = False) 

# (x_train, t_train): 학습 데이터셋의 Data, Label(정답값)
# (x_test, t_test): 테스트 데이터셋의 Data, Label(정답값)

x_train # array([[0, 0, 0, ..., 0, 0, 0],
                #[0, 0, 0, ..., 0, 0, 0],
                #[0, 0, 0, ..., 0, 0, 0],
                #...,
                #[0, 0, 0, ..., 0, 0, 0],
                #[0, 0, 0, ..., 0, 0, 0],
                #[0, 0, 0, ..., 0, 0, 0]], dtype=uint8)

t_train # array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
```

```python
# x_train[3] 이미지로 추론 진행

# data와 label 변수 저장
img = x_train[3] 
label = t_train[3]

# 이미지를 1차원 넘파이 배열로 저장했으므로 이미지를 다시 표시하기 위해 28*28 크기로 다시 변형
x_train[3].shape # (784,)
img_1=img.reshape(28,28) 

print(img_1.shape) # (28, 28)
print(label) # 1
img_show(img_1)
```

![image](https://user-images.githubusercontent.com/100326309/160082391-d2ff43cb-5845-4351-92fa-f842749000a2.png)



2. **신경망 구현**

- 입력층 뉴런 784개(원소의 갯수), 출력층 뉴론 10개로 구성 (0~9 까지 판정)
  - `Input` (1 * 784) -> `Layer1` (50개 뉴런) -> `Layer2` (100개 뉴런) -> `Output Layer` (10개 node)

```python
# 구현에 사용할 모든 함수 정의
import pickle

# 이미지 데이터 불러와 test데이터셋 반환
def get_data():
    (x_train, t_train),(x_test, t_test) = load_mnist(flatten = True, normalize = False)
    return x_test,t_test

# pickle에서 network파일에 저장되어 있는 '학습된 가중치 매개변수' 읽어오기
def init_network():
    with open(".\code\ch03\sample_weight.pkl","rb") as f:
        network = pickle.load(f)
    return network # 딕셔너리 형태( W : 가중치)

# 시그모이드 함수 -> 0~1의 확률값
def sigmoid(x):
    return 1/(1+np.exp(-x))

# 소프트맥스 함수 -> 합이 1인 확률값
def softmax(a):
    c=np.max(a)
    exp_a=np.exp(a-c) # 오버플로 대책
    sum_exp_a = np.sum(exp_a)
    y = exp_a/sum_exp_a
    return y

# 추론 함수: 분류를 시행해줌
def predict(network,x):
    W1, W2, W3 = network['W1'],network['W2'],network['W3']
    b1, b2, b3 = network['b1'],network['b2'],network['b3']
    
    a1 = np.dot(x,W1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1,W2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2,W3) + b3
    y = softmax(a3)
    
    return y # 각 레이블의 확률을 넘파이 배열로 반환. 
             # ex) [0.1, 0.3, ...] 이라면, 이미지가 숫자 0일 확률은 10%
```

```python
# 가중치 값을 알 수 있는 network 변수 탐색하기
network = init_network()

type(network) # dict
network['W1'].shape # (784, 50)
network['W2'].shape # (50, 100)
network['W3'].shape # (100, 10)

network['b1'].shape # (50,)
network['b2'].shape  # (100,)
network['b3'].shape # (10,)
```



3. **추론 수행 및 정확도 평가**

- `np.argmax()`: axis에 해당하는 값들 중 가장 큰 값의 인덱스를 반환 (axis = 0: x축 기준, axis = 1: y축 기준, axis = 2: z축 기준 )

```python
# MNIST 데이터 셋을 얻고 네트워크를 생성
x,t = get_data()
network = init_network()
accuracy_cnt = 0

# for 문을 돌려 x에 저장된 이미지 데이터를 1장씩 꺼내 predict() 함수로 분류
for i in range(len(x)):
    y = predict(network,x[i]) # 이미지가 속할 확률값이 저장된 넘파이 배열 반환
    p = np.argmax(y) # 배열에서 값이 가장 큰 원소의 인덱스를 구하기
    if p == t[i]: # 정확도 평가
        accuracy_cnt += 1
        
# 정확도 출력
print("Accuracy:" + str(float(accuracy_cnt) / len(x))) # Accuracy:0.9207
```



### 4. 배치 처리 방식

- 배치 처리: 한꺼번에 최대한 많은 이미지를 병렬처리하는 것
  - 배치: 하나로 묶은 입력데이터
  - 장점: 데이터 처리 속도 빠름. 작은데이터를 여러번 반복해서 처리하는것보다 큰 배열을 한꺼번에 계산하는것이 더 효율적이기 때문

- 미니배치: 컴퓨터의 성능에 한계가 있으므로 가능한 최대로 많은 이미지를 보기 위해 batch size를 지정
  - ex) batch size = 100이라면,  한번에 100장의 이미지를 처리
  - 밑의 예시에서는 앞에서부터 100개씩 묶는 방식으로 묶기

```python
# 배치 사이즈 지정: 이전 코드는 이미지를 한장씩 끊어서 처리. 미니배치 처리를 통해 이미지를 100장씩 끊어서 처리
batch_size = 100

# 정확도 변수 생성: 최솟값 0에서 시작
accuracy_cnt = 0

# 예측 수행 
for i in range(0, len(x), batch_size):
    x_batch = x[i:i+batch_size]  # range() 함수가 반환하는 리스트를 바탕으로 데이터 100개씩 묶기
                                 # x[0,100], x[100:200], ... 와 같이 앞에서부터 100장씩
    #print(x_batch[1])
    y_batch = predict(network, x_batch)
    p = np.argmax(y_batch, axis=1)
    accuracy_cnt += np.sum(p == t[i:i+batch_size])

# 예측 정확도 출력
print("Accuracy:"+str(float(accuracy_cnt)/ len(x))) # Accuracy:0.9207
```

- 앞에서부터 100장씩 뽑는 것이 아니라, `random.choice()` 함수를 이용하여 무작위로 100장을 뽑는다면?

```python
# 미니배치 처리
train_size = x_train.shape[0] # 60000
batch_size = 100

batch_mask = np.random.choice(train_size, batch_size) #60,000중 100개의 숫자를 무작위로 추출

x_batch = x_train[batch_mask] # 추출한 숫자를 인덱스로 사용하여 데이터를 추출
t_batch = t_train[batch_mask]

# x_batch, t_batch 데이터 탐색
x_batch.shape # (100, 784)
x_batch[0].ndim # 1
```



---

그림 출처: 밑바닥부터 시작하는 딥러닝
